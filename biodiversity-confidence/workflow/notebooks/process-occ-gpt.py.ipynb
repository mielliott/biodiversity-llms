{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and grade LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job parameters:\n",
      "- Responses to analyze: ../../results/idigbio-sample/gpt-4-1106-preview/occurrence/responses.tsv\n",
      "- Query phrasings (count: 6):\n",
      "    - \"Can species {genus} {specificepithet} be found in {county}, {stateprovince}, {country}?\"\n",
      "    - \"Is it possible to encounter species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
      "    - \"Is there a presence of species {genus} {specificepithet} within {county}, {stateprovince}, {country}?\"\n",
      "    - \"Does {county}, {stateprovince}, {country} harbor species {genus} {specificepithet}?\"\n",
      "    - \"Is species {genus} {specificepithet} present in {county}, {stateprovince}, {country}?\"\n",
      "    - \"Can one observe species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
      "- Query fields:\n",
      "    - \"kingdom\"\n",
      "    - \"phylum\"\n",
      "    - \"family\"\n",
      "    - \"genus\"\n",
      "    - \"specificepithet\"\n",
      "    - \"country\"\n",
      "    - \"stateprovince\"\n",
      "    - \"county\"\n"
     ]
    }
   ],
   "source": [
    "class InputFiles(NamedTuple):\n",
    "    responses: str\n",
    "    taxonomy_scores: str\n",
    "    taxonomy: str\n",
    "    record_counts_by_phylum: str\n",
    "    record_counts_by_family: str\n",
    "    record_counts_by_genus: str\n",
    "    record_counts_by_species: str\n",
    "    record_counts_by_stateprovince: str\n",
    "    record_counts_by_county: str\n",
    "\n",
    "class OutputFiles(NamedTuple):\n",
    "    results_with_ums: str\n",
    "\n",
    "class Env(NamedTuple):\n",
    "    input_files: InputFiles\n",
    "    output_files: OutputFiles\n",
    "    num_phrasings: int\n",
    "    phrasings: list[str]\n",
    "    query_fields: list[str]\n",
    "    seed: int\n",
    "    only_valid_absences: bool\n",
    "\n",
    "if \"snakemake\" in globals():\n",
    "    env = Env(\n",
    "        input_files=snakemake.input,\n",
    "        output_files=snakemake.output,\n",
    "        num_phrasings=len(snakemake.params.phrasings),\n",
    "        phrasings=snakemake.params.phrasings,\n",
    "        query_fields=snakemake.params.query_fields,\n",
    "        seed=snakemake.params.seed,\n",
    "        only_valid_absences=snakemake.params.validate_absences\n",
    "    )\n",
    "else: # Fill in parameters manually for testing outside of snakemake\n",
    "    import os\n",
    "    ROOT = os.path.expanduser(\"~/biodiversity-llms\")\n",
    "    # LLM = \"gpt-3.5-turbo-0125\"\n",
    "    LLM = \"gpt-4-1106-preview\"\n",
    "\n",
    "    env = Env(\n",
    "        input_files = InputFiles(\n",
    "            f\"../../results/idigbio-sample/{LLM}/occurrence/responses.tsv\",\n",
    "            f\"../../results/idigbio-sample/{LLM}/taxonomy/summary.tsv\",\n",
    "            \"../../results/idigbio-sample/input/taxa-genus.tsv\",\n",
    "            \"../../results/idigbio-sample/input/record-counts-by-phylum.tsv\",\n",
    "            \"../../results/idigbio-sample/input/record-counts-by-family.tsv\",\n",
    "            \"../../results/idigbio-sample/input/record-counts-by-genus.tsv\",\n",
    "            \"../../results/idigbio-sample/input/record-counts-by-species.tsv\",\n",
    "            \"../../results/idigbio-sample/input/record-counts-by-stateprovince.tsv\",\n",
    "            \"../../results/idigbio-sample/input/record-counts-by-county.tsv\",\n",
    "        ),\n",
    "        output_files = OutputFiles(\n",
    "            results_with_ums=f\"../../results/idigbio-sample/{LLM}/results-with-ums.tsv\"\n",
    "        ),\n",
    "        num_phrasings=6,\n",
    "        phrasings=[\n",
    "            \"Can species {genus} {specificepithet} be found in {county}, {stateprovince}, {country}?\",\n",
    "            \"Is it possible to encounter species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\",\n",
    "            \"Is there a presence of species {genus} {specificepithet} within {county}, {stateprovince}, {country}?\",\n",
    "            \"Does {county}, {stateprovince}, {country} harbor species {genus} {specificepithet}?\",\n",
    "            \"Is species {genus} {specificepithet} present in {county}, {stateprovince}, {country}?\",\n",
    "            \"Can one observe species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
    "        ],\n",
    "        query_fields=[\n",
    "            \"kingdom\",\n",
    "            \"phylum\",\n",
    "            \"family\",\n",
    "            \"genus\",\n",
    "            \"specificepithet\",\n",
    "            \"country\",\n",
    "            \"stateprovince\",\n",
    "            \"county\"\n",
    "        ],\n",
    "        seed=69847,\n",
    "        only_valid_absences=True\n",
    "    )\n",
    "\n",
    "def nest(level, strings):\n",
    "    separator = \"\\n\" + \"  \" * level + \"- \"\n",
    "    return separator + separator.join([str(s) for s in strings])\n",
    "\n",
    "def quote(strings):\n",
    "    return [f'\"{s}\"' for s in strings]\n",
    "\n",
    "print(\"Job parameters:\")\n",
    "print(f\"- Responses to analyze: {env.input_files.responses}\")\n",
    "print(f\"- Query phrasings (count: {env.num_phrasings}):{nest(2, quote(env.phrasings))}\")\n",
    "print(f\"- Query fields:{nest(2, quote(env.query_fields))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpfg_class_order = pd.read_csv(open(env.input_files.taxonomy, \"r\"), sep=\"\\t\")\\\n",
    "    .set_index([\"kingdom\", \"phylum\", \"family\", \"taxon\"])[[\"class\", \"order\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1180588/1573875467.py:15: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  df[[\"class\", \"order\"]] = df.apply(axis=1, func=lambda r: kpfg_class_order.loc[r[\"kingdom\"], r[\"phylum\"], r[\"family\"], r[\"genus\"]].iloc[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23,334 records\n",
      "140,004 queries (#records x #phrasings)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>specificepithet</th>\n",
       "      <th>country</th>\n",
       "      <th>stateprovince</th>\n",
       "      <th>county</th>\n",
       "      <th>present</th>\n",
       "      <th>responses</th>\n",
       "      <th>...</th>\n",
       "      <th>order</th>\n",
       "      <th>phrasing</th>\n",
       "      <th>query id</th>\n",
       "      <th>response id</th>\n",
       "      <th>scores</th>\n",
       "      <th>yesnos</th>\n",
       "      <th>abstains</th>\n",
       "      <th>prediction</th>\n",
       "      <th>target</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>animalia</td>\n",
       "      <td>porifera</td>\n",
       "      <td>microcionidae</td>\n",
       "      <td>clathria</td>\n",
       "      <td>aculeofila</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Nayarit</td>\n",
       "      <td>Bahia De Banderas</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No No No No No No No No No No</td>\n",
       "      <td>...</td>\n",
       "      <td>poecilosclerida</td>\n",
       "      <td>1</td>\n",
       "      <td>5999046189242602981</td>\n",
       "      <td>-3707963387680935750</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    kingdom    phylum         family     genus specificepithet country  \\\n",
       "7  animalia  porifera  microcionidae  clathria      aculeofila  Mexico   \n",
       "\n",
       "  stateprovince             county present                      responses  \\\n",
       "7       Nayarit  Bahia De Banderas     Yes  No No No No No No No No No No   \n",
       "\n",
       "   ...            order  phrasing             query id          response id  \\\n",
       "7  ...  poecilosclerida         1  5999046189242602981 -3707963387680935750   \n",
       "\n",
       "  scores  yesnos  abstains  prediction  target  correct  \n",
       "7      0      10         0          -1       1       -1  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_item(values, item):\n",
    "    counts = dict(Counter(values).most_common())\n",
    "    return counts[item] if item in counts else 0\n",
    "\n",
    "def make_id(df):\n",
    "    return df.apply(lambda r: hash(\"\".join([str(v) for v in r.values]).lower()), axis=1)\n",
    "\n",
    "def get_results(responses):\n",
    "    df = pd.read_csv(open(responses), sep=\"\\t\")\n",
    "\n",
    "    df[\"genus\"] = df[\"genus\"].str.lower()\n",
    "    df = df[df[\"family\"] != df[\"genus\"]]\n",
    "\n",
    "    df[[\"class\", \"order\"]] = df.apply(axis=1, func=lambda r: kpfg_class_order.loc[r[\"kingdom\"], r[\"phylum\"], r[\"family\"], r[\"genus\"]].iloc[0])\n",
    "\n",
    "    df[\"phrasing\"] = df[\"question number\"].astype(int) % env.num_phrasings\n",
    "    df[\"query id\"] = make_id(df[env.query_fields])\n",
    "\n",
    "    df[\"response id\"] = make_id(df[[\"query id\", \"phrasing\"]])\n",
    "    df = df.groupby(\"response id\").head(1) # Drop responses for repeated questions\n",
    "\n",
    "    df[\"scores\"] = df[\"responses\"].apply(lambda r: count_item(r.lower().split(), \"yes\"))\n",
    "    df[\"yesnos\"] = df[\"responses\"].apply(lambda r: count_item(r.lower().split(), \"yes\") + count_item(r.lower().split(), \"no\"))\n",
    "    df[\"abstains\"] = 10 - df[\"yesnos\"]\n",
    "\n",
    "    df[\"prediction\"] = df[\"scores\"].apply(lambda x: -1 if x == 0 else 1)\n",
    "    df[\"target\"] = (df[\"present\"] == \"Yes\").astype(int) * 2 - 1\n",
    "    df[\"correct\"] = df[\"prediction\"] * df[\"target\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "UNUSED_FIELDS = [\"query\"]\n",
    "res = get_results(env.input_files.responses)\\\n",
    "    .drop(columns=UNUSED_FIELDS)\n",
    "\n",
    "print(f\"{len(res) / env.num_phrasings:,.0f} records\")\n",
    "print(f\"{len(res):,.0f} queries (#records x #phrasings)\")\n",
    "res.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy threshold: between 0 - 0.01\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_decision_threshold():\n",
    "    def decision(x):\n",
    "        return x.astype(int) * 2 - 1\n",
    "\n",
    "    scores = res[\"scores\"]\n",
    "    thresholds = np.arange(scores.min(), scores.max(), (scores.max() - scores.min()) / 1000)\n",
    "    accuracies = np.array(list(map(lambda t: (decision(scores >= t) == res[\"target\"]).mean(), thresholds)))\n",
    "    best_accuracy_threshold = accuracies.argmax()\n",
    "    print(f\"Best accuracy threshold: between {thresholds[best_accuracy_threshold - 1]:.1g} - {thresholds[best_accuracy_threshold]:.1g}\")\n",
    "find_optimal_decision_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query-level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_data = pd.read_csv(open(env.input_files.taxonomy_scores, \"r\"), sep=\"\\t\")\\\n",
    "    .set_index([\"subject_rank\", \"taxon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_rank  taxon         \n",
       "class         actinopterygii    1.0\n",
       "              amphibia          1.0\n",
       "              angiospermae      1.0\n",
       "Name: rank exact match mean, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tax_scores = tax_data[\"rank exact match mean\"]\n",
    "tax_scores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_rank  taxon         \n",
       "class         actinopterygii    0.0\n",
       "              amphibia          0.0\n",
       "              angiospermae      0.0\n",
       "Name: garbage responses, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tax_garbage_counts = tax_data[\"garbage responses\"]\n",
    "tax_garbage_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_rank\n",
       "class     0.196970\n",
       "family    0.183433\n",
       "genus     0.645909\n",
       "Name: garbage responses, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_tax_garbage_counts = tax_garbage_counts.groupby(\"subject_rank\").mean()\n",
    "average_tax_garbage_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_rank\n",
       "class     0.875758\n",
       "family    0.846596\n",
       "genus     0.752374\n",
       "order     0.844753\n",
       "phylum    1.000000\n",
       "Name: rank exact match mean, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_tax_scores = tax_scores.groupby(\"subject_rank\").mean()\n",
    "average_tax_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record_counts(path, fields):\n",
    "    df = pd.read_csv(open(path, \"r\"), sep=\"\\t\")\n",
    "    if \"genus\" in df.columns:\n",
    "        df[\"genus\"] = df[\"genus\"].str.lower()\n",
    "    return df.groupby(fields)[\"record count\"].first()\n",
    "\n",
    "record_counts_by_phylum = get_record_counts(env.input_files.record_counts_by_phylum, [\"kingdom\", \"phylum\"])\n",
    "record_counts_by_family = get_record_counts(env.input_files.record_counts_by_family, [\"kingdom\", \"phylum\", \"family\"])\n",
    "record_counts_by_genus = get_record_counts(env.input_files.record_counts_by_genus, [\"kingdom\", \"phylum\", \"family\", \"genus\"])\n",
    "record_counts_by_species = get_record_counts(env.input_files.record_counts_by_species, [\"kingdom\", \"phylum\", \"family\", \"genus\", \"specificepithet\"])\n",
    "record_counts_by_stateprovince = get_record_counts(env.input_files.record_counts_by_stateprovince, [\"country\", \"stateprovince\"])\n",
    "record_counts_by_county = get_record_counts(env.input_files.record_counts_by_county, [\"country\", \"stateprovince\", \"county\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasing_avg_pred = res.groupby(\"query id\")[\"prediction\"].mean()\n",
    "phrasing_var_score = res.groupby(\"query id\")[\"scores\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_823fa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Phrasing</th>\n",
       "      <th id=\"T_823fa_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_823fa_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_823fa_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_823fa_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_823fa_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_823fa_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_823fa_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_823fa_row0_col0\" class=\"data row0 col0\" >64.28%</td>\n",
       "      <td id=\"T_823fa_row0_col1\" class=\"data row0 col1\" >64.54%</td>\n",
       "      <td id=\"T_823fa_row0_col2\" class=\"data row0 col2\" >64.55%</td>\n",
       "      <td id=\"T_823fa_row0_col3\" class=\"data row0 col3\" >64.19%</td>\n",
       "      <td id=\"T_823fa_row0_col4\" class=\"data row0 col4\" >64.10%</td>\n",
       "      <td id=\"T_823fa_row0_col5\" class=\"data row0 col5\" >63.86%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb2d6b57ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0d5ec\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual presence</th>\n",
       "      <th id=\"T_0d5ec_level0_col0\" class=\"col_heading level0 col0\" >Absent</th>\n",
       "      <th id=\"T_0d5ec_level0_col1\" class=\"col_heading level0 col1\" >Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0d5ec_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_0d5ec_row0_col0\" class=\"data row0 col0\" >86.41%</td>\n",
       "      <td id=\"T_0d5ec_row0_col1\" class=\"data row0 col1\" >43.44%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb2c838e8a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_64c80\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted presence</th>\n",
       "      <th id=\"T_64c80_level0_col0\" class=\"col_heading level0 col0\" >Absent</th>\n",
       "      <th id=\"T_64c80_level0_col1\" class=\"col_heading level0 col1\" >Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_64c80_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_64c80_row0_col0\" class=\"data row0 col0\" >58.93%</td>\n",
       "      <td id=\"T_64c80_row0_col1\" class=\"data row0 col1\" >77.30%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb2d71a6210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e3533\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Kingdom</th>\n",
       "      <th id=\"T_e3533_level0_col0\" class=\"col_heading level0 col0\" >animalia</th>\n",
       "      <th id=\"T_e3533_level0_col1\" class=\"col_heading level0 col1\" >plantae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e3533_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_e3533_row0_col0\" class=\"data row0 col0\" >63.87%</td>\n",
       "      <td id=\"T_e3533_row0_col1\" class=\"data row0 col1\" >64.74%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb2d4920500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_accuracies(df, field, title, remap_values={}, format=\"{:,.2%}\"):\n",
    "    df = pd.DataFrame(\n",
    "        (df.groupby(field)[\"correct\"].mean() * .5 + .5)\n",
    "        .rename(\"Response accuracy\")\n",
    "    ).transpose()\n",
    "    df.columns.name = title\n",
    "    df.rename(columns=remap_values, inplace=True)\n",
    "\n",
    "    display(df.style.format(format))\n",
    "\n",
    "show_accuracies(res, \"phrasing\", \"Phrasing\")\n",
    "show_accuracies(res, \"target\", \"Actual presence\", remap_values={-1: \"Absent\", 1: \"Present\"})\n",
    "show_accuracies(res, \"prediction\", \"Predicted presence\", remap_values={-1: \"Absent\", 1: \"Present\"})\n",
    "show_accuracies(res, \"kingdom\", \"Kingdom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def trim_county_name(county):\n",
    "    parts = county.split()\n",
    "    if len(parts) > 1 and re.sub(r'[^\\w]', '', parts[-1]).lower() in (\"co\", \"county\", \"mun\", \"par\", \"prov\"):\n",
    "        return \" \".join(parts[:-1])\n",
    "    else:\n",
    "        return county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = res[res[\"phrasing\"] == 0]\n",
    "\n",
    "def get_ums(instance):\n",
    "    # TODO: condition um3 on prediction?\n",
    "    num_responses = 10 - instance[\"abstains\"]\n",
    "    global r\n",
    "    r = instance\n",
    "\n",
    "    # Higher values = more certainty\n",
    "    return pd.Series({\n",
    "        # Scores\n",
    "        \"um1_total_score\": instance[\"scores\"] if instance[\"prediction\"] == 1 else num_responses - instance[\"scores\"],\n",
    "        \"um1_percent_score\": (instance[\"scores\"] if instance[\"prediction\"] == 1 else num_responses - instance[\"scores\"]) / max(1, num_responses),\n",
    "\n",
    "        # Abstains\n",
    "        \"um2_abstains\": num_responses,\n",
    "\n",
    "        # Sensitivity to phrasing\n",
    "        \"um4_phrasing_agreement\": phrasing_avg_pred[instance[\"query id\"]] * instance[\"prediction\"],\n",
    "        \"um4_phrasing_score_var\": phrasing_var_score[instance[\"query id\"]] * -1,\n",
    "\n",
    "        # iDigBio record counts by taxonomic ranks\n",
    "        # \"um5_record_count_by_kingdom\": taxon_record_counts[\"kingdomCount\"],\n",
    "        \"um5_record_count_by_phylum\": record_counts_by_phylum.loc[instance[\"kingdom\"], instance[\"phylum\"]],\n",
    "        \"um5_record_count_by_family\": record_counts_by_family.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"]],\n",
    "        \"um5_record_count_by_genus\": record_counts_by_genus.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"], instance[\"genus\"]],\n",
    "        \"um5_record_count_by_species\": record_counts_by_species.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"], instance[\"genus\"], instance[\"specificepithet\"]],\n",
    "        \"um5_record_count_by_stateprovince\": record_counts_by_stateprovince.loc[instance[\"country\"], instance[\"stateprovince\"]],\n",
    "        \"um5_record_count_by_county\": record_counts_by_county.loc[instance[\"country\"], instance[\"stateprovince\"], trim_county_name(instance[\"county\"])],\n",
    "\n",
    "        # Accuracy on taxonomy questions\n",
    "        \"um6_taxqa_accuracy_by_phylum\": tax_scores[\"phylum\"].get(instance[\"phylum\"], average_tax_scores[\"phylum\"]),\n",
    "        \"um6_taxqa_accuracy_by_class\": tax_scores[\"class\"].get(instance[\"class\"], average_tax_scores[\"class\"]),\n",
    "        \"um6_taxqa_accuracy_by_order\": tax_scores[\"order\"].get(instance[\"order\"], average_tax_scores[\"order\"]),\n",
    "        \"um6_taxqa_accuracy_by_family\": tax_scores[\"family\"].get(instance[\"family\"], average_tax_scores[\"family\"]),\n",
    "        \"um6_taxqa_accuracy_by_genus\": tax_scores[\"genus\"].get(instance[\"genus\"], average_tax_scores[\"genus\"]),\n",
    "\n",
    "        # Number of yes-no responses to taxonomy questions\n",
    "        \"um7_taxqa_responses_by_phylum\": -tax_garbage_counts[\"phylum\"].get(instance[\"phylum\"], average_tax_garbage_counts[\"phylum\"]) / 10,\n",
    "        \"um7_taxqa_responses_by_class\": -tax_garbage_counts[\"class\"].get(instance[\"class\"], average_tax_garbage_counts[\"class\"]) / 20,\n",
    "        \"um7_taxqa_responses_by_order\": -tax_garbage_counts[\"order\"].get(instance[\"order\"], average_tax_garbage_counts[\"order\"]) / 30,\n",
    "        \"um7_taxqa_responses_by_family\": -tax_garbage_counts[\"family\"].get(instance[\"family\"], average_tax_garbage_counts[\"family\"]) / 40,\n",
    "        \"um7_taxqa_responses_by_genus\": -tax_garbage_counts[\"genus\"].get(instance[\"genus\"], average_tax_garbage_counts[\"genus\"]) / 50,\n",
    "    })\n",
    "\n",
    "full_df = pd.concat([df.apply(lambda row: get_ums(row), axis=1), df], axis=1)\n",
    "full_df.to_csv(env.output_files.results_with_ums, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
