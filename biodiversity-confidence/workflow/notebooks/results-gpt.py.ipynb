{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and grade LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from typing import NamedTuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job parameters:\n",
      "- Responses to analyze: ../../results/gpt-4-1106-preview/all-shuffled.tsv\n",
      "- Query phrasings (count: 6):\n",
      "    - \"Can species {genus} {specificepithet} be found in {county}, {stateprovince}, {country}?\"\n",
      "    - \"Is it possible to encounter species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
      "    - \"Is there a presence of species {genus} {specificepithet} within {county}, {stateprovince}, {country}?\"\n",
      "    - \"Does {county}, {stateprovince}, {country} harbor species {genus} {specificepithet}?\"\n",
      "    - \"Is species {genus} {specificepithet} present in {county}, {stateprovince}, {country}?\"\n",
      "    - \"Can one observe species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
      "- Query fields:\n",
      "    - \"kingdom\"\n",
      "    - \"phylum\"\n",
      "    - \"family\"\n",
      "    - \"genus\"\n",
      "    - \"specificepithet\"\n",
      "    - \"country\"\n",
      "    - \"stateprovince\"\n",
      "    - \"county\"\n"
     ]
    }
   ],
   "source": [
    "class InputFiles(NamedTuple):\n",
    "    responses: str\n",
    "    taxonomy_scores: str\n",
    "    taxon_counts: str\n",
    "    train_test_split: str\n",
    "\n",
    "class OutputFiles(NamedTuple):\n",
    "    results_with_ums: str\n",
    "\n",
    "class Env(NamedTuple):\n",
    "    input_files: InputFiles\n",
    "    output_files: OutputFiles\n",
    "    num_phrasings: int\n",
    "    phrasings: list[str]\n",
    "    query_fields: list[str]\n",
    "    seed: int\n",
    "    only_valid_absences: bool\n",
    "\n",
    "if \"snakemake\" in globals():\n",
    "    env = Env(\n",
    "        input_files=snakemake.input,\n",
    "        output_files=snakemake.output,\n",
    "        num_phrasings=len(snakemake.params.phrasings),\n",
    "        phrasings=snakemake.params.phrasings,\n",
    "        query_fields=snakemake.params.query_fields,\n",
    "        seed=snakemake.params.seed,\n",
    "        only_valid_absences=snakemake.params.validate_absences\n",
    "    )\n",
    "else: # Fill in parameters manually for testing outside of snakemake\n",
    "    import os\n",
    "    ROOT = os.path.expanduser(\"~/biodiversity-llms\")\n",
    "    LLM = \"gpt-4-1106-preview\"\n",
    "\n",
    "    env = Env(\n",
    "        input_files = InputFiles(\n",
    "            responses=f\"../../results/{LLM}/all-shuffled.tsv\",\n",
    "            taxonomy_scores=ROOT + \"/tdwg2023/taxonomy/results/kpfg_scores.tsv\",\n",
    "            taxon_counts=ROOT + \"/tdwg2023/taxonomy/results/taxon-counts.tsv\",\n",
    "            train_test_split=\"../../results/input/train_test_split.tsv\"\n",
    "        ),\n",
    "        output_files = OutputFiles(\n",
    "            results_with_ums=f\"../../results/{LLM}/results-with-ums.tsv\"\n",
    "        ),\n",
    "        num_phrasings=6,\n",
    "        phrasings=[\n",
    "            \"Can species {genus} {specificepithet} be found in {county}, {stateprovince}, {country}?\",\n",
    "            \"Is it possible to encounter species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\",\n",
    "            \"Is there a presence of species {genus} {specificepithet} within {county}, {stateprovince}, {country}?\",\n",
    "            \"Does {county}, {stateprovince}, {country} harbor species {genus} {specificepithet}?\",\n",
    "            \"Is species {genus} {specificepithet} present in {county}, {stateprovince}, {country}?\",\n",
    "            \"Can one observe species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
    "        ],\n",
    "        query_fields=[\n",
    "            \"kingdom\",\n",
    "            \"phylum\",\n",
    "            \"family\",\n",
    "            \"genus\",\n",
    "            \"specificepithet\",\n",
    "            \"country\",\n",
    "            \"stateprovince\",\n",
    "            \"county\"\n",
    "        ],\n",
    "        seed=69847,\n",
    "        only_valid_absences=True\n",
    "    )\n",
    "\n",
    "def nest(level, strings):\n",
    "    separator = \"\\n\" + \"  \" * level + \"- \"\n",
    "    return separator + separator.join([str(s) for s in strings])\n",
    "\n",
    "def quote(strings):\n",
    "    return [f'\"{s}\"' for s in strings]\n",
    "\n",
    "print(\"Job parameters:\")\n",
    "print(f\"- Responses to analyze: {env.input_files.responses}\")\n",
    "print(f\"- Query phrasings (count: {env.num_phrasings}):{nest(2, quote(env.phrasings))}\")\n",
    "print(f\"- Query fields:{nest(2, quote(env.query_fields))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../results/gpt-4-1106-preview/all-shuffled.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     27\u001b[0m UNUSED_FIELDS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mUNUSED_FIELDS)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(res)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39menv\u001b[38;5;241m.\u001b[39mnum_phrasings\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(res)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m queries (#records x #phrasings)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mget_results\u001b[0;34m(responses, train_test_split)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_results\u001b[39m(responses, train_test_split):\n\u001b[1;32m      9\u001b[0m     train_test_split \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28mopen\u001b[39m(train_test_split), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m)\u001b[49m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmerge(train_test_split, on\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mquery_fields)\n\u001b[1;32m     12\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrasing\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion number\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m%\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_phrasings\n\u001b[1;32m     13\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m make_id(df[env\u001b[38;5;241m.\u001b[39mquery_fields])\n",
      "File \u001b[0;32m~/mambaforge/envs/llm/lib/python3.12/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../results/gpt-4-1106-preview/all-shuffled.tsv'"
     ]
    }
   ],
   "source": [
    "def count_item(values, item):\n",
    "    counts = dict(Counter(values).most_common())\n",
    "    return counts[item] if item in counts else 0\n",
    "\n",
    "def make_id(df):\n",
    "    return df.apply(lambda r: hash(\"\".join([str(v) for v in r.values]).lower()), axis=1)\n",
    "\n",
    "def get_results(responses, train_test_split):\n",
    "    train_test_split = pd.read_csv(open(train_test_split), sep=\"\\t\", index_col=0)\n",
    "    df = pd.read_csv(open(responses), sep=\"\\t\").merge(train_test_split, on=env.query_fields)\n",
    "\n",
    "    df[\"phrasing\"] = df[\"question number\"].astype(int) % env.num_phrasings\n",
    "    df[\"query id\"] = make_id(df[env.query_fields])\n",
    "\n",
    "    df[\"response id\"] = make_id(df[[\"query id\", \"phrasing\"]])\n",
    "    df = df.groupby(\"response id\").head(1) # Drop responses for repeated questions\n",
    "\n",
    "    df[\"scores\"] = df[\"responses\"].apply(lambda r: count_item(r.lower().split(), \"yes\"))\n",
    "    df[\"yesnos\"] = df[\"responses\"].apply(lambda r: count_item(r.lower().split(), \"yes\") + count_item(r.lower().split(), \"no\"))\n",
    "    df[\"abstains\"] = 10 - df[\"yesnos\"]\n",
    "\n",
    "    df[\"prediction\"] = df[\"scores\"].apply(lambda x: -1 if x == 0 else 1)\n",
    "    df[\"correct\"] = df[\"prediction\"] * df[\"target\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "UNUSED_FIELDS = [\"query\"]\n",
    "res = get_results(env.input_files.responses, env.input_files.train_test_split)\\\n",
    "    .drop(columns=UNUSED_FIELDS)\n",
    "\n",
    "print(f\"{len(res) / env.num_phrasings:,.0f} records\")\n",
    "print(f\"{len(res):,.0f} queries (#records x #phrasings)\")\n",
    "res.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy threshold: between 0 - 0.01\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_decision_threshold():\n",
    "    def decision(x):\n",
    "        return x.astype(int) * 2 - 1\n",
    "\n",
    "    scores = res[\"scores\"]\n",
    "    thresholds = np.arange(scores.min(), scores.max(), (scores.max() - scores.min()) / 1000)\n",
    "    accuracies = np.array(list(map(lambda t: (decision(scores >= t) == res[\"target\"]).mean(), thresholds)))\n",
    "    best_accuracy_threshold = accuracies.argmax()\n",
    "    print(f\"Best accuracy threshold: between {thresholds[best_accuracy_threshold - 1]:.1g} - {thresholds[best_accuracy_threshold]:.1g}\")\n",
    "find_optimal_decision_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query-level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject rank</th>\n",
       "      <th>taxon</th>\n",
       "      <th>num_correct</th>\n",
       "      <th>num_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family</td>\n",
       "      <td>acaulosporaceae</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family</td>\n",
       "      <td>acroporidae</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family</td>\n",
       "      <td>agaricaceae</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>family</td>\n",
       "      <td>amphiuridae</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>apidae</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>phylum</td>\n",
       "      <td>porifera</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>phylum</td>\n",
       "      <td>rhodophyta</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>phylum</td>\n",
       "      <td>spermatophyta</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>phylum</td>\n",
       "      <td>tracheophyta</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>phylum</td>\n",
       "      <td>zygomycota</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject rank            taxon  num_correct  num_response\n",
       "0          family  acaulosporaceae         31.0          36.0\n",
       "1          family      acroporidae         40.0          40.0\n",
       "2          family      agaricaceae         36.0          36.0\n",
       "3          family      amphiuridae         30.0          30.0\n",
       "4          family           apidae         40.0          40.0\n",
       "...           ...              ...          ...           ...\n",
       "2281       phylum         porifera         10.0          10.0\n",
       "2282       phylum       rhodophyta          7.0           7.0\n",
       "2283       phylum    spermatophyta          0.0          10.0\n",
       "2284       phylum     tracheophyta         10.0          10.0\n",
       "2285       phylum       zygomycota         10.0          10.0\n",
       "\n",
       "[2286 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(open(env.input_files.taxonomy_scores, \"r\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpfg_scores = pd.read_csv(open(env.input_files.taxonomy_scores, \"r\"), sep=\"\\t\")\n",
    "kpfg_scores[\"accuracy\"] = (1 + kpfg_scores[\"num_correct\"]) / (2 + kpfg_scores[\"num_response\"])\n",
    "kpfg_scores = kpfg_scores.set_index([\"subject rank\", \"taxon\"])\n",
    "average_kpfg_scores = kpfg_scores.groupby(\"subject rank\").sum().apply(lambda r: r[\"num_correct\"] / r[\"num_response\"], axis=1)\n",
    "average_kpfg_responses = kpfg_scores.groupby(\"subject rank\")[\"num_response\"].mean()\n",
    "\n",
    "record_counts_by_taxon = pd.read_csv(open(env.input_files.taxon_counts, \"r\"), sep=\"\\t\").set_index([\"kingdom\", \"phylum\", \"family\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasing_avg_pred = res.groupby(\"query id\")[\"prediction\"].mean()\n",
    "phrasing_var_score = res.groupby(\"query id\")[\"scores\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b867c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Phrasing</th>\n",
       "      <th id=\"T_b867c_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_b867c_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_b867c_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_b867c_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_b867c_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_b867c_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b867c_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_b867c_row0_col0\" class=\"data row0 col0\" >64.30%</td>\n",
       "      <td id=\"T_b867c_row0_col1\" class=\"data row0 col1\" >64.11%</td>\n",
       "      <td id=\"T_b867c_row0_col2\" class=\"data row0 col2\" >64.48%</td>\n",
       "      <td id=\"T_b867c_row0_col3\" class=\"data row0 col3\" >64.20%</td>\n",
       "      <td id=\"T_b867c_row0_col4\" class=\"data row0 col4\" >63.88%</td>\n",
       "      <td id=\"T_b867c_row0_col5\" class=\"data row0 col5\" >63.73%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd5a997e3c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7a86d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Actual presence</th>\n",
       "      <th id=\"T_7a86d_level0_col0\" class=\"col_heading level0 col0\" >Absent</th>\n",
       "      <th id=\"T_7a86d_level0_col1\" class=\"col_heading level0 col1\" >Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7a86d_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_7a86d_row0_col0\" class=\"data row0 col0\" >86.31%</td>\n",
       "      <td id=\"T_7a86d_row0_col1\" class=\"data row0 col1\" >43.56%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd5aadfb6b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0b64f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Predicted presence</th>\n",
       "      <th id=\"T_0b64f_level0_col0\" class=\"col_heading level0 col0\" >Absent</th>\n",
       "      <th id=\"T_0b64f_level0_col1\" class=\"col_heading level0 col1\" >Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b64f_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_0b64f_row0_col0\" class=\"data row0 col0\" >58.61%</td>\n",
       "      <td id=\"T_0b64f_row0_col1\" class=\"data row0 col1\" >77.47%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd5a99addf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_377eb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Kingdom</th>\n",
       "      <th id=\"T_377eb_level0_col0\" class=\"col_heading level0 col0\" >animalia</th>\n",
       "      <th id=\"T_377eb_level0_col1\" class=\"col_heading level0 col1\" >plantae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_377eb_level0_row0\" class=\"row_heading level0 row0\" >Response accuracy</th>\n",
       "      <td id=\"T_377eb_row0_col0\" class=\"data row0 col0\" >63.79%</td>\n",
       "      <td id=\"T_377eb_row0_col1\" class=\"data row0 col1\" >64.54%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd5aadfb6b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_accuracies(df, field, title, remap_values={}, format=\"{:,.2%}\"):\n",
    "    df = pd.DataFrame(\n",
    "        (df.groupby(field)[\"correct\"].mean() * .5 + .5)\n",
    "        .rename(\"Response accuracy\")\n",
    "    ).transpose()\n",
    "    df.columns.name = title\n",
    "    df.rename(columns=remap_values, inplace=True)\n",
    "\n",
    "    display(df.style.format(format))\n",
    "\n",
    "show_accuracies(res, \"phrasing\", \"Phrasing\")\n",
    "show_accuracies(res, \"target\", \"Actual presence\", remap_values={-1: \"Absent\", 1: \"Present\"})\n",
    "show_accuracies(res, \"prediction\", \"Predicted presence\", remap_values={-1: \"Absent\", 1: \"Present\"})\n",
    "show_accuracies(res, \"kingdom\", \"Kingdom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_by_field(d, field, prior_counts=1) -> pd.Series:\n",
    "    def fill_blanks(series):\n",
    "        return series.reindex(d[field].unique(), fill_value=0)\n",
    "    \n",
    "    subset = d[\"train\"]\n",
    "    num_correct = prior_counts + fill_blanks(d[subset * (d[\"correct\"] == 1)].groupby(field).size())\n",
    "    num_incorrect = prior_counts + fill_blanks(d[subset * (d[\"correct\"] == -1)].groupby(field).size())\n",
    "\n",
    "    return num_correct / (num_correct + num_incorrect)\n",
    "\n",
    "df = res[res[\"phrasing\"] == 0]\n",
    "\n",
    "acc_by_rank = pd.Series({rank: get_acc_by_field(df, rank) for rank in [\"kingdom\", \"phylum\", \"family\"]})\n",
    "acc_by_country = get_acc_by_field(df, \"country\")\n",
    "acc_by_stateprovince = get_acc_by_field(df, \"stateprovince\")\n",
    "\n",
    "def get_ums(instance):\n",
    "    # TODO: condition um3 on prediction?\n",
    "    um1_present = instance[\"scores\"]\n",
    "    um1_absent = 1 if um1_present == 0 else 0\n",
    "    taxon_record_counts = record_counts_by_taxon.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"]]\n",
    "\n",
    "    # Positively oriented, i.e. higher values = more certainty\n",
    "    return pd.Series({\n",
    "        # Scores\n",
    "        \"um1_present_score\": um1_present,\n",
    "        \"um1_absent_score\": um1_absent,\n",
    "        \"um1_either\": um1_present + um1_absent,\n",
    "        \n",
    "        # Abstains\n",
    "        \"um2_percent_abstains\": 1.0 - instance[\"abstains\"] / 10.0,\n",
    "\n",
    "        # Performance by field values\n",
    "        # Note: defaults to 0.5 if no data (TODO)\n",
    "        \"um3_accuracy_by_kingdom\": acc_by_rank[\"kingdom\"][instance[\"kingdom\"]],\n",
    "        \"um3_accuracy_by_phylum\": acc_by_rank[\"phylum\"][instance[\"phylum\"]],\n",
    "        \"um3_accuracy_by_family\": acc_by_rank[\"family\"][instance[\"family\"]],\n",
    "        \"um3_accuracy_by_country\": acc_by_country[instance[\"country\"]],\n",
    "        \"um3_accuracy_by_stateprovince\": acc_by_stateprovince[instance[\"stateprovince\"]],\n",
    "\n",
    "        # Sensitivity to phrasing\n",
    "        \"um4_phrasing_agreement\": phrasing_avg_pred[instance[\"query id\"]] * -instance[\"prediction\"],\n",
    "        \"um4_phrasing_score_var\": phrasing_var_score[instance[\"query id\"]],\n",
    "\n",
    "        # iDigBio record counts by taxonomic ranks\n",
    "        \"um5_record_count_by_kingdom\": taxon_record_counts[\"kingdomCount\"],\n",
    "        \"um5_record_count_by_phylum\": taxon_record_counts[\"phylumCount\"],\n",
    "        \"um5_record_count_by_family\": taxon_record_counts[\"familyCount\"],\n",
    "        # \"um5_record_count_by_country\": country_record_count,\n",
    "        # \"um5_record_count_by_stateprovince\": stateprovince_record_count,\n",
    "\n",
    "        # Accuracy on taxonomy questions\n",
    "        \"um6_taxqa_accuracy_by_phylum\": kpfg_scores[\"accuracy\"][\"phylum\"].get(instance[\"phylum\"].lower(), average_kpfg_scores[\"phylum\"]),\n",
    "        \"um6_taxqa_accuracy_by_family\": kpfg_scores[\"accuracy\"][\"family\"].get(instance[\"family\"].lower(), average_kpfg_scores[\"family\"]),\n",
    "        \"um6_taxqa_accuracy_by_genus\": kpfg_scores[\"accuracy\"][\"genus\"].get(instance[\"genus\"].lower(), average_kpfg_scores[\"genus\"]),\n",
    "\n",
    "        # Number of yes-no responses to taxonomy questions\n",
    "        \"um7_taxqa_responses_by_phylum\": kpfg_scores[\"num_response\"][\"phylum\"].get(instance[\"phylum\"].lower(), average_kpfg_responses[\"phylum\"]) / 10,\n",
    "        \"um7_taxqa_responses_by_family\": kpfg_scores[\"num_response\"][\"family\"].get(instance[\"family\"].lower(), average_kpfg_responses[\"family\"]) / 40,\n",
    "        \"um7_taxqa_responses_by_genus\": kpfg_scores[\"num_response\"][\"genus\"].get(instance[\"genus\"].lower(), average_kpfg_responses[\"genus\"]) / 50,\n",
    "    })\n",
    "\n",
    "full_df = pd.concat([df.apply(lambda row: get_ums(row), axis=1), df], axis=1)\n",
    "full_df.to_csv(env.output_files.results_with_ums)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
