{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from collections import Counter\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continental_counties(path_to_state_counties_tsv, path_to_counties_shp, path_to_states_shp):\n",
    "    state_name_map = gpd.read_file(path_to_states_shp)[[\"STATEFP\", \"NAME\"]].set_index(\"STATEFP\")[\"NAME\"]\n",
    "\n",
    "    df = pd.read_csv(path_to_state_counties_tsv, sep=\"\\t\")[[\"state\", \"county\"]]\n",
    "    df = df.set_index(df[\"state\"] + \", \" + df[\"county\"])\n",
    "\n",
    "    gdf = gpd.read_file(path_to_counties_shp)[[\"STATEFP\", \"NAMELSAD\", \"geometry\"]]\n",
    "    gdf = gdf.set_index(gdf[\"STATEFP\"].apply(lambda x: state_name_map[x]) + \", \" + gdf[\"NAMELSAD\"])\n",
    "\n",
    "    return gdf.join(df, how=\"right\")[[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama, Autauga County</th>\n",
       "      <td>POLYGON ((-86.58826 32.36775, -86.58834 32.367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama, Baldwin County</th>\n",
       "      <td>POLYGON ((-87.97692 31.08658, -87.97688 31.087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama, Barbour County</th>\n",
       "      <td>POLYGON ((-85.41585 31.68164, -85.41619 31.677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama, Bibb County</th>\n",
       "      <td>POLYGON ((-86.87657 33.01891, -86.87657 33.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama, Blount County</th>\n",
       "      <td>POLYGON ((-86.56421 33.80194, -86.56556 33.801...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  geometry\n",
       "Alabama, Autauga County  POLYGON ((-86.58826 32.36775, -86.58834 32.367...\n",
       "Alabama, Baldwin County  POLYGON ((-87.97692 31.08658, -87.97688 31.087...\n",
       "Alabama, Barbour County  POLYGON ((-85.41585 31.68164, -85.41619 31.677...\n",
       "Alabama, Bibb County     POLYGON ((-86.87657 33.01891, -86.87657 33.018...\n",
       "Alabama, Blount County   POLYGON ((-86.56421 33.80194, -86.56556 33.801..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_df = get_continental_counties(\\\n",
    "    \"../resources/us-maps/us-state-counties.tsv\",\n",
    "    \"../resources/us-maps/tl_2022_us_county/tl_2022_us_county.shp\",\n",
    "    \"../resources/us-maps/tl_2022_us_state/tl_2022_us_state.shp\")\n",
    "us_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "def train_conf_model(train_df, features):\n",
    "    return HistGradientBoostingClassifier(\n",
    "        loss='log_loss',\n",
    "        learning_rate=0.01,\n",
    "        min_samples_leaf=10,\n",
    "        max_iter=200,\n",
    "        monotonic_cst=np.ones_like(features, dtype=int)\n",
    "    ).fit(train_df[features], train_df[\"correct\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num uncertainty measures: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "pattern = re.compile(\"^um[0-9]+_.+\")\n",
    "\n",
    "df = sugarmaple\n",
    "features = [c for c in df.columns if pattern.match(c) is not None]\n",
    "\n",
    "print(\"Num uncertainty measures:\", len(features))\n",
    "print(\"\\n\".join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def plot_scores(dfs: list, name, score_field=\"score\", dpi=150):\n",
    "    if type(dfs) != list:\n",
    "        dfs = [dfs]\n",
    "    \n",
    "    f, ax = plt.subplots(1,1, figsize=(8,6), sharex=True, sharey=True, dpi=dpi)\n",
    "    plt.title(f\"Occurrence map of {name}\")\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\",pad=0,alpha=0.5)\n",
    "    for df in dfs:\n",
    "        df.plot(score_field, ax=ax, alpha=0.5, cmap='Reds', edgecolor='k', legend=True, cax=cax, linewidth=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFiles(NamedTuple):\n",
    "    taxonomy_scores: str\n",
    "    taxonomy: str\n",
    "    record_counts_by_phylum: str\n",
    "    record_counts_by_family: str\n",
    "    record_counts_by_genus: str\n",
    "    record_counts_by_species: str\n",
    "    record_counts_by_stateprovince: str\n",
    "    record_counts_by_county: str\n",
    "\n",
    "class OutputFiles(NamedTuple):\n",
    "    results_with_ums: str\n",
    "\n",
    "class Env(NamedTuple):\n",
    "    input_files: InputFiles\n",
    "    output_files: OutputFiles\n",
    "    num_phrasings: int\n",
    "    phrasings: list[str]\n",
    "    query_fields: list[str]\n",
    "    seed: int\n",
    "\n",
    "if \"snakemake\" in globals():\n",
    "    env = Env(\n",
    "        input_files=snakemake.input,\n",
    "        output_files=snakemake.output,\n",
    "        num_phrasings=len(snakemake.params.phrasings),\n",
    "        phrasings=snakemake.params.phrasings,\n",
    "        query_fields=snakemake.params.query_fields,\n",
    "        seed=snakemake.params.seed\n",
    "    )\n",
    "else: # Fill in parameters manually for testing outside of snakemake\n",
    "    import os\n",
    "    ROOT = os.path.expanduser(\"~/biodiversity-llms\")\n",
    "    # LLM = \"gpt-3.5-turbo-0125\"\n",
    "    LLM = \"gpt-4-1106-preview\"\n",
    "\n",
    "    RESULTS = \"../results\"\n",
    "    env = Env(\n",
    "        input_files = InputFiles(\n",
    "            f\"{RESULTS}/us-maps/{LLM}/taxonomy/summary.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/taxa-genus.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/record-counts-by-phylum.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/record-counts-by-family.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/record-counts-by-genus.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/record-counts-by-species.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/record-counts-by-stateprovince.tsv\",\n",
    "            f\"{RESULTS}/us-maps/input/record-counts-by-county.tsv\",\n",
    "        ),\n",
    "        output_files = OutputFiles(\n",
    "            results_with_ums=f\"{RESULTS}/us-maps/{LLM}/results-with-ums.tsv\"\n",
    "        ),\n",
    "        num_phrasings=6,\n",
    "        phrasings=[\n",
    "            \"Can species {genus} {specificepithet} be found in {county}, {stateprovince}, {country}?\",\n",
    "            \"Is it possible to encounter species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\",\n",
    "            \"Is there a presence of species {genus} {specificepithet} within {county}, {stateprovince}, {country}?\",\n",
    "            \"Does {county}, {stateprovince}, {country} harbor species {genus} {specificepithet}?\",\n",
    "            \"Is species {genus} {specificepithet} present in {county}, {stateprovince}, {country}?\",\n",
    "            \"Can one observe species {genus} {specificepithet} in {county}, {stateprovince}, {country}?\"\n",
    "        ],\n",
    "        query_fields=[\n",
    "            \"kingdom\",\n",
    "            \"phylum\",\n",
    "            \"family\",\n",
    "            \"genus\",\n",
    "            \"specificepithet\",\n",
    "            \"country\",\n",
    "            \"stateprovince\",\n",
    "            \"county\"\n",
    "        ],\n",
    "        seed=69847\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,436 records\n",
      "74,616 queries (#records x #phrasings)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>stateprovince</th>\n",
       "      <th>county</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>specificepithet</th>\n",
       "      <th>responses</th>\n",
       "      <th>input token count</th>\n",
       "      <th>...</th>\n",
       "      <th>question number</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>phrasing</th>\n",
       "      <th>query id</th>\n",
       "      <th>response id</th>\n",
       "      <th>scores</th>\n",
       "      <th>yesnos</th>\n",
       "      <th>abstains</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>plantae</td>\n",
       "      <td>tracheophyta</td>\n",
       "      <td>sapindaceae</td>\n",
       "      <td>acer</td>\n",
       "      <td>saccharum</td>\n",
       "      <td>No No No No No No No No No No</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>magnoliopsida</td>\n",
       "      <td>sapindales</td>\n",
       "      <td>0</td>\n",
       "      <td>-1877092219711042595</td>\n",
       "      <td>9006511588438991320</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         country stateprovince          county  kingdom        phylum  \\\n",
       "0  United States       Alabama  Autauga County  plantae  tracheophyta   \n",
       "\n",
       "        family genus specificepithet                      responses  \\\n",
       "0  sapindaceae  acer       saccharum  No No No No No No No No No No   \n",
       "\n",
       "   input token count  ...  question number          class       order  \\\n",
       "0                 31  ...                0  magnoliopsida  sapindales   \n",
       "\n",
       "  phrasing             query id          response id  scores  yesnos  \\\n",
       "0        0 -1877092219711042595  9006511588438991320       0      10   \n",
       "\n",
       "   abstains  prediction  \n",
       "0         0          -1  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_item(values, item):\n",
    "    counts = dict(Counter(values).most_common())\n",
    "    return counts[item] if item in counts else 0\n",
    "\n",
    "def make_id(df):\n",
    "    return df.apply(lambda r: hash(\"\".join([str(v) for v in r.values]).lower()), axis=1)\n",
    "\n",
    "def get_results(responses):\n",
    "    df = pd.read_csv(responses, sep=\"\\t\")\n",
    "    \n",
    "    df[\"genus\"] = df[\"genus\"].str.lower()\n",
    "    df = df[df[\"family\"] != df[\"genus\"]]\n",
    "\n",
    "    df[[\"class\", \"order\"]] = df.apply(axis=1, func=lambda r: kpfg_class_order.loc[r[\"kingdom\"], r[\"phylum\"], r[\"family\"], r[\"genus\"]])\n",
    "\n",
    "    df[\"phrasing\"] = df[\"question number\"].astype(int) % env.num_phrasings\n",
    "    df[\"query id\"] = make_id(df[env.query_fields])\n",
    "\n",
    "    df[\"response id\"] = make_id(df[[\"query id\", \"phrasing\"]])\n",
    "    df = df.groupby(\"response id\").head(1) # Drop responses for repeated questions\n",
    "\n",
    "    df[\"scores\"] = df[\"responses\"].apply(lambda r: count_item(r.lower().split(), \"yes\"))\n",
    "    df[\"yesnos\"] = df[\"responses\"].apply(lambda r: count_item(r.lower().split(), \"yes\") + count_item(r.lower().split(), \"no\"))\n",
    "    df[\"abstains\"] = 10 - df[\"yesnos\"]\n",
    "\n",
    "    df[\"prediction\"] = df[\"scores\"].apply(lambda x: -1 if x == 0 else 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "kpfg_class_order = pd.read_csv(open(env.input_files.taxonomy, \"r\"), sep=\"\\t\")\\\n",
    "    .set_index([\"kingdom\", \"phylum\", \"family\", \"taxon\"])[[\"class\", \"order\"]]\n",
    "\n",
    "UNUSED_FIELDS = [\"query\"]\n",
    "\n",
    "responses_path = \"../results/us-maps/gpt-4-1106-preview/occurrence/responses.tsv\"\n",
    "res = get_results(responses_path)\\\n",
    "    .drop(columns=UNUSED_FIELDS)\n",
    "\n",
    "print(f\"{len(res) / env.num_phrasings:,.0f} records\")\n",
    "print(f\"{len(res):,.0f} queries (#records x #phrasings)\")\n",
    "res.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasing_avg_pred = res.groupby(\"query id\")[\"prediction\"].mean()\n",
    "phrasing_var_score = res.groupby(\"query id\")[\"scores\"].var()\n",
    "\n",
    "tax_data = pd.read_csv(open(env.input_files.taxonomy_scores, \"r\"), sep=\"\\t\")\\\n",
    "    .set_index([\"subject_rank\", \"taxon\"])\n",
    "\n",
    "tax_scores = tax_data[\"rank exact match mean\"]\n",
    "tax_garbage_counts = tax_data[\"garbage responses\"]\n",
    "\n",
    "average_tax_garbage_counts = tax_garbage_counts.groupby(\"subject_rank\").mean()\n",
    "average_tax_scores = tax_scores.groupby(\"subject_rank\").mean()\n",
    "\n",
    "def get_record_counts(path, fields):\n",
    "    df = pd.read_csv(open(path, \"r\"), sep=\"\\t\")\n",
    "    if \"genus\" in df.columns:\n",
    "        df[\"genus\"] = df[\"genus\"].str.lower()\n",
    "    return df.groupby(fields)[\"record count\"].first()\n",
    "\n",
    "record_counts_by_phylum = get_record_counts(env.input_files.record_counts_by_phylum, [\"kingdom\", \"phylum\"])\n",
    "record_counts_by_family = get_record_counts(env.input_files.record_counts_by_family, [\"kingdom\", \"phylum\", \"family\"])\n",
    "record_counts_by_genus = get_record_counts(env.input_files.record_counts_by_genus, [\"kingdom\", \"phylum\", \"family\", \"genus\"])\n",
    "record_counts_by_species = get_record_counts(env.input_files.record_counts_by_species, [\"kingdom\", \"phylum\", \"family\", \"genus\", \"specificepithet\"])\n",
    "record_counts_by_stateprovince = get_record_counts(env.input_files.record_counts_by_stateprovince, [\"country\", \"stateprovince\"])\n",
    "record_counts_by_county = get_record_counts(env.input_files.record_counts_by_county, [\"country\", \"stateprovince\", \"county\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def trim_county_name(county):\n",
    "    parts = county.split()\n",
    "    if len(parts) > 1 and re.sub(r'[^\\w]', '', parts[-1]).lower() in (\"co\", \"county\", \"mun\", \"par\", \"prov\"):\n",
    "        return \" \".join(parts[:-1])\n",
    "    else:\n",
    "        return county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ums(instance):\n",
    "    # TODO: condition um3 on prediction?\n",
    "    num_responses = 10 - instance[\"abstains\"]\n",
    "    global r\n",
    "    r = instance\n",
    "\n",
    "    # Higher values = more certainty\n",
    "    return pd.Series({\n",
    "        # Scores\n",
    "        \"um1_total_score\": instance[\"scores\"] if instance[\"prediction\"] == 1 else num_responses - instance[\"scores\"],\n",
    "        \"um1_percent_score\": (instance[\"scores\"] if instance[\"prediction\"] == 1 else num_responses - instance[\"scores\"]) / max(1, num_responses),\n",
    "\n",
    "        # Abstains\n",
    "        \"um2_abstains\": num_responses,\n",
    "\n",
    "        # Sensitivity to phrasing\n",
    "        \"um4_phrasing_agreement\": phrasing_avg_pred[instance[\"query id\"]] * instance[\"prediction\"],\n",
    "        \"um4_phrasing_score_var\": phrasing_var_score[instance[\"query id\"]] * -1,\n",
    "\n",
    "        # iDigBio record counts by taxonomic ranks\n",
    "        # \"um5_record_count_by_kingdom\": taxon_record_counts[\"kingdomCount\"],\n",
    "        \"um5_record_count_by_phylum\": record_counts_by_phylum.loc[instance[\"kingdom\"], instance[\"phylum\"]],\n",
    "        \"um5_record_count_by_family\": record_counts_by_family.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"]],\n",
    "        \"um5_record_count_by_genus\": record_counts_by_genus.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"], instance[\"genus\"]],\n",
    "        \"um5_record_count_by_species\": record_counts_by_species.loc[instance[\"kingdom\"], instance[\"phylum\"], instance[\"family\"], instance[\"genus\"], instance[\"specificepithet\"]],\n",
    "        \"um5_record_count_by_stateprovince\": record_counts_by_stateprovince.loc[instance[\"country\"], instance[\"stateprovince\"]],\n",
    "        \"um5_record_count_by_county\": record_counts_by_county.loc[instance[\"country\"], instance[\"stateprovince\"], trim_county_name(instance[\"county\"])],\n",
    "\n",
    "        # Accuracy on taxonomy questions\n",
    "        \"um6_taxqa_accuracy_by_phylum\": tax_scores[\"phylum\"].get(instance[\"phylum\"], average_tax_scores[\"phylum\"]),\n",
    "        \"um6_taxqa_accuracy_by_class\": tax_scores[\"class\"].get(instance[\"class\"], average_tax_scores[\"class\"]),\n",
    "        \"um6_taxqa_accuracy_by_order\": tax_scores[\"order\"].get(instance[\"order\"], average_tax_scores[\"order\"]),\n",
    "        \"um6_taxqa_accuracy_by_family\": tax_scores[\"family\"].get(instance[\"family\"], average_tax_scores[\"family\"]),\n",
    "        \"um6_taxqa_accuracy_by_genus\": tax_scores[\"genus\"].get(instance[\"genus\"], average_tax_scores[\"genus\"]),\n",
    "\n",
    "        # Number of yes-no responses to taxonomy questions\n",
    "        \"um7_taxqa_responses_by_phylum\": -tax_garbage_counts[\"phylum\"].get(instance[\"phylum\"], average_tax_garbage_counts[\"phylum\"]) / 10,\n",
    "        \"um7_taxqa_responses_by_class\": -tax_garbage_counts[\"class\"].get(instance[\"class\"], average_tax_garbage_counts[\"class\"]) / 20,\n",
    "        \"um7_taxqa_responses_by_order\": -tax_garbage_counts[\"order\"].get(instance[\"order\"], average_tax_garbage_counts[\"order\"]) / 30,\n",
    "        \"um7_taxqa_responses_by_family\": -tax_garbage_counts[\"family\"].get(instance[\"family\"], average_tax_garbage_counts[\"family\"]) / 40,\n",
    "        \"um7_taxqa_responses_by_genus\": -tax_garbage_counts[\"genus\"].get(instance[\"genus\"], average_tax_garbage_counts[\"genus\"]) / 50,\n",
    "    })\n",
    "\n",
    "df = res[res[\"phrasing\"] == 0]\n",
    "full_df = pd.concat([df.apply(lambda row: get_ums(row), axis=1), df], axis=1)\n",
    "full_df.to_csv(env.output_files.results_with_ums, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
