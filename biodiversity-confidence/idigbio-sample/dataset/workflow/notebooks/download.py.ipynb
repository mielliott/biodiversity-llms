{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a dataset of iDigBio records using the following algorithm:\n",
    "\n",
    "```\n",
    "parameter: target_total_family_count\n",
    "parameter: target_family_record_count\n",
    "\n",
    "sorted_phyla <- sort phyla by *ascending* family count\n",
    "\n",
    "num_phyla_remaining <- size(phyla)\n",
    "for each phylum in sorted_phyla {\n",
    "    target_family_count <- floor(target_total_family_count / num_phyla_remaining)\n",
    "    family_record_counts <- count records for each family\n",
    "    families <- get families under phylum with sufficient number of records\n",
    "\n",
    "    family_bins <- place families into bins of similar record counts\n",
    "    sorted_family_bins <- sort bins by *ascending* family count\n",
    "\n",
    "    num_bins_remaining <- size(family_bins)\n",
    "    for each bin in sorted_family_bins {\n",
    "        target_family_count <- floor(target_family_count / num_bins_remaining)\n",
    "        sorted_families <- sort families in bin by *descending* record count\n",
    "        \n",
    "        family_count <- 0\n",
    "        for family in bin while family_count < target_family_count {\n",
    "            family_records <- get diverse sample of records for family\n",
    "            if size(family_records) > target_family_record_count {\n",
    "                save family_records\n",
    "                increment family_count\n",
    "            }\n",
    "        }\n",
    "\n",
    "        decrement num_bins_remaining\n",
    "    }\n",
    "\n",
    "    decrement num_phyla_remaining\n",
    "}\n",
    "```\n",
    "\n",
    "Algorithm for sampling a diverse set of records for each family:\n",
    "* Get list of unique species, county pairs\n",
    "* Collect one record per pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"snakemake\" in globals():\n",
    "    print(\"Parameters:\", dict(snakemake.params))\n",
    "    records_path = snakemake.output[0]\n",
    "    kingdom = snakemake.params.kingdom\n",
    "    phyla = snakemake.params.phyla\n",
    "    min_records_per_family = snakemake.params.min_records_per_family\n",
    "    max_records_per_family = snakemake.params.max_records_per_family\n",
    "    families_per_kingdom = snakemake.params.families_per_kingdom\n",
    "    required_fields = snakemake.params.required_fields\n",
    "else:\n",
    "    records_path = \"test.jsonl\"\n",
    "    kingdom = \"plantae\"\n",
    "    phyla = {\"tracheophyta\", \"bryophyta\", \"marchantiophyta\", \"rhodophyta\", \"chlorophyta\", \"charophyta\", \"anthocerotophyta\"}\n",
    "    min_records_per_family = 25\n",
    "    max_records_per_family = 200\n",
    "    families_per_kingdom = 168\n",
    "    required_fields = [\"kingdom\", \"family\", \"genus\", \"specificepithet\", \"countrycode\", \"stateprovince\", \"county\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records per kingdom: between 4200 and 33600\n",
      "Families per kingdom: 168\n",
      "Number of phyla: 7\n",
      "Families per phylum: 24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Records per kingdom: between {min_records_per_family * families_per_kingdom} and {max_records_per_family * families_per_kingdom}\")\n",
    "print(\"Families per kingdom:\", families_per_kingdom)\n",
    "\n",
    "phyla_in_kingdom = len(phyla)\n",
    "families_per_phylum = int(families_per_kingdom / phyla_in_kingdom)\n",
    "print(\"Number of phyla:\", phyla_in_kingdom)\n",
    "print(\"Families per phylum:\", families_per_phylum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import math\n",
    "import numpy as np\n",
    "from attr import dataclass\n",
    "\n",
    "api = \"https://beta-search.idigbio.org/v2\"\n",
    "\n",
    "required_fields_rq = {field: {\"type\": \"exists\"} for field in required_fields}\n",
    "default_rq = required_fields_rq | {\n",
    "    \"taxonrank\": \"species\"\n",
    "}\n",
    "\n",
    "def get_idigbio_summary(rq, top_fields, count, rf=required_fields, verbose=False):\n",
    "    response = requests.post(f\"{api}/summary/top/records\", json=dict(\n",
    "        rq=default_rq | rq,\n",
    "        top_fields=top_fields,\n",
    "        count=count\n",
    "    ))\n",
    "\n",
    "    return response.json()[top_fields[0]]\n",
    "\n",
    "# limit=5000 is the max allowed by the APIs\n",
    "def get_idigbio_records(rq, limit=5000, gt_uuid=None, api=api):\n",
    "    data = {\n",
    "        \"rq\": default_rq | rq,\n",
    "        \"limit\": limit,\n",
    "    }\n",
    "\n",
    "    if gt_uuid is not None:\n",
    "        data[\"rq\"] |= {\"uuid\": {\"type\": \"range\", \"gt\": gt_uuid}}\n",
    "        data |= {\n",
    "            \"sort\": [{ \"uuid\": \"asc\" }]\n",
    "        }\n",
    "\n",
    "    response = requests.post(f\"{api}/search/records\", json=data)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class SpeciesCounty():\n",
    "    species: str\n",
    "    county: str\n",
    "\n",
    "    bad_names = {\n",
    "        \"incertae sedis\",\n",
    "        \"na\",\n",
    "        \"no\",\n",
    "        \"no data\",\n",
    "        \"no disponible\",\n",
    "        \"not available\",\n",
    "        \"not given\",\n",
    "        \"not specified\",\n",
    "        \"not stated\",\n",
    "        \"undetermined\",\n",
    "        \"unknown\",\n",
    "        \"unspecified\",\n",
    "        \"unstated\",\n",
    "        \"species\",\n",
    "        \"scientific name\",\n",
    "        \"country\",\n",
    "        \"state\",\n",
    "        \"province\",\n",
    "        \"stateprovince\",\n",
    "        \"county\",\n",
    "    }\n",
    "\n",
    "    def _get_simplified_species_name_parts(self):\n",
    "        return [s for s in self.species.split() if (\n",
    "            len(s) > 0 and\n",
    "            s[0].isalnum()\n",
    "        )][:2]\n",
    "\n",
    "    def _get_simplified_county_name_parts(self):\n",
    "        county = (\n",
    "            re.sub(\"[\\\\(\\\\[].*?[\\\\)\\\\]]\", \"\", self.county)\n",
    "            .replace(\".\", \"\")\n",
    "        )\n",
    "\n",
    "        raw_parts = [s for s in county.split()]\n",
    "        return [s for s in raw_parts if (\n",
    "            len(s) > 1 and\n",
    "            s[0].isalnum() and\n",
    "            s not in {\n",
    "                \"co\",\n",
    "                \"county\",\n",
    "                \"pref\",\n",
    "                \"prefecture\",\n",
    "                \"i\",\n",
    "                \"island\",\n",
    "                \"mun\",\n",
    "                \"municipio\",\n",
    "                \"municipality\",\n",
    "                \"dis\",\n",
    "                \"dist\",\n",
    "                \"distr\"\n",
    "                \"district\",\n",
    "                \"div\",\n",
    "                \"division\"\n",
    "                \"reg\",\n",
    "                \"region\",\n",
    "                \"group\",\n",
    "                \"prov\",\n",
    "                \"province\",\n",
    "                \"rayon\", # Russia\n",
    "                \"raion\",\n",
    "                \"kn\", # Sweden\n",
    "                \"department\",\n",
    "                \"par\",\n",
    "                \"parish\",\n",
    "                \"bezirk\", # Switzerland\n",
    "                \"census\",\n",
    "                \"area\",\n",
    "                \"land\",\n",
    "                \"council\",\n",
    "                \"admin\"\n",
    "                \"admin.\",\n",
    "                \"administrative\",\n",
    "                \"administration\",\n",
    "                \"administrasi\",\n",
    "                \"metro\",\n",
    "                \"metro.\",\n",
    "                \"metropolitan\",\n",
    "                \"barrio\",\n",
    "                \"burrow\",\n",
    "                \"borough\",\n",
    "                \"raya\",\n",
    "                \"regency\",\n",
    "                \"kabupaten\",\n",
    "                \"auto\",\n",
    "                \"autonomous\"\n",
    "            }\n",
    "        )]\n",
    "    \n",
    "    def __init__(self, species, county):\n",
    "        self.species = species.lower()\n",
    "        self.county = county.lower()\n",
    "\n",
    "        species_name_parts = self._get_simplified_species_name_parts()\n",
    "        county_name_parts = self._get_simplified_county_name_parts()\n",
    "\n",
    "        self.simple_species_name = \" \".join(species_name_parts)\n",
    "        self.simple_county_name = \" \".join(county_name_parts)\n",
    "\n",
    "        self.valid = (\n",
    "            self.simple_species_name not in self.bad_names and\n",
    "            self.simple_county_name not in self.bad_names and\n",
    "            len(species_name_parts) == 2 and\n",
    "            len(county_name_parts) > 0\n",
    "        )\n",
    "\n",
    "    def ok(self):\n",
    "        return self.valid\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Use clean county names to test equivalence, but preserve the original uncleaned names to\n",
    "        maintain record retrievability\n",
    "        \"\"\"\n",
    "        return hash(f\"{self.simple_species_name}\\t{self.simple_county_name}\")\n",
    "\n",
    "    def __eq__(self, value: object) -> bool:\n",
    "        return isinstance(value, self.__class__) and hash(self) == hash(value)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"SpeciesCounty({self.county}, {self.species})\"\n",
    "\n",
    "\n",
    "assert len(set([\n",
    "    SpeciesCounty(\"big bug\", \"alachua\"),\n",
    "    SpeciesCounty(\"big bug l.\", \"alachua co.\"),\n",
    "    SpeciesCounty(\"big bug l. 1788\", \"alachua county [but not really]\"),\n",
    "])) == 1\n",
    "\n",
    "assert SpeciesCounty(\"[the species]\", \"hah\").ok() == False\n",
    "assert SpeciesCounty(\"the species\", \"[hah]\").ok() == False\n",
    "assert SpeciesCounty(\"incertae sedis\", \"baker\").ok() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeciesCounty(svennevad, hypnum pratense)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_family_species_county_pairs(kingdom, family):\n",
    "    family_summary = get_idigbio_summary(\n",
    "        rq= {\n",
    "            \"kingdom\": kingdom,\n",
    "            \"family\": family,\n",
    "            \"basisofrecord\": \"preservedspecimen\",\n",
    "            \"taxonrank\": \"species\"\n",
    "        },\n",
    "        top_fields=[\"phylum\", \"scientificname\", \"county\"],\n",
    "        count=max_records_per_family,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    unique_species_county_pairs = {\n",
    "        sc\n",
    "        for family, family_data in family_summary.items()\n",
    "        for species, species_data in family_data[\"scientificname\"].items()\n",
    "        for county, county_data in species_data[\"county\"].items()\n",
    "        for sc in (SpeciesCounty(species.lower(), county.lower()),)\n",
    "        if sc.ok()\n",
    "    }\n",
    "\n",
    "    return list(unique_species_county_pairs)\n",
    "\n",
    "\n",
    "list(get_family_species_county_pairs(\"plantae\", \"stereodontaceae\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['uuid', 'type', 'etag', 'data', 'indexTerms'])\n"
     ]
    }
   ],
   "source": [
    "def get_record_for_species_county(kingdom: str, species_county: SpeciesCounty) -> dict:\n",
    "    return get_idigbio_records(\n",
    "        rq={\n",
    "            \"kingdom\": kingdom,\n",
    "            \"scientificname\": species_county.species,\n",
    "            \"county\": species_county.county\n",
    "        },\n",
    "        limit=1\n",
    "    )[\"items\"][0]\n",
    "\n",
    "\n",
    "def get_species_county_records(kingdom, sc_pairs, count):\n",
    "    shuffle_index = np.random.permutation(len(sc_pairs))[:count]\n",
    "    for sc in (sc_pairs[i] for i in shuffle_index):\n",
    "        yield get_record_for_species_county(kingdom, sc)\n",
    "\n",
    "\n",
    "# Example use:\n",
    "if True:\n",
    "    sc_pairs = get_family_species_county_pairs(\"plantae\", \"stereodontaceae\")\n",
    "    print(next(iter(get_species_county_records(\"plantae\", sc_pairs, 1))).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylum_summaries = get_idigbio_summary(\n",
    "    rq={\n",
    "        \"kingdom\": kingdom,\n",
    "        \"phylum\": list(phyla)\n",
    "    },\n",
    "    top_fields=[\"phylum\", \"family\"],\n",
    "    count=families_per_kingdom,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# For families that appear in more than one phylum, assign them to the phylum for which\n",
    "# they have the most records\n",
    "all_family_phylum_assignments = dict()\n",
    "family_record_counts_by_phylum = dict()\n",
    "\n",
    "for phylum, data in phylum_summaries.items():\n",
    "    family_counts = dict(map(lambda x: (x[0], x[1][\"itemCount\"]), data[\"family\"].items()))\n",
    "\n",
    "    for family, count in family_counts.items():\n",
    "        current_count = family_record_counts_by_phylum.get(family, 0)\n",
    "        if count > current_count:\n",
    "            all_family_phylum_assignments[family] = phylum\n",
    "            family_record_counts_by_phylum[family] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anthocerotophyta': 4,\n",
       " 'charophyta': 9,\n",
       " 'chlorophyta': 60,\n",
       " 'marchantiophyta': 65,\n",
       " 'rhodophyta': 79,\n",
       " 'bryophyta': 122,\n",
       " 'tracheophyta': 168}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_family_candidates(phylum, phylum_family_counts):\n",
    "    bad_family_names = {\n",
    "        \"\",\n",
    "        \"\\\"\\\"\",\n",
    "        \"unknown\",\n",
    "        \"unplaced county\",\n",
    "    }\n",
    "    \n",
    "    def check_family_name(family_name: str, family_summary: dict):\n",
    "        return (family_name.lower() not in bad_family_names and\n",
    "                all_family_phylum_assignments[family_name] == phylum and\n",
    "                family_summary[\"itemCount\"] >= min_records_per_family)\n",
    "    \n",
    "    return {f: v[\"itemCount\"] for f, v in phylum_family_counts.items() if check_family_name(f, v)}\n",
    "\n",
    "\n",
    "# 1. For each phylum\n",
    "# - Get family candidates\n",
    "# - Count family candidates\n",
    "phylum_family_candidates = {phylum: get_family_candidates(phylum, data[\"family\"]) for phylum, data in phylum_summaries.items()}\n",
    "phylum_family_counts = {phylum: len(family_counts) for phylum, family_counts in phylum_family_candidates.items()}\n",
    "\n",
    "# 2. Sort phyla by family count, ascending\n",
    "phylum_family_counts = dict(sorted(phylum_family_counts.items(), key=lambda kv: (kv[1], kv[0])))\n",
    "phylum_family_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_family_bins_with_ascending_size(family_sc_counts, num_bins):\n",
    "    sc_counts = list(family_sc_counts.values())\n",
    "\n",
    "    if len(sc_counts) == 0:\n",
    "        return []\n",
    "\n",
    "    # Bin families by record count\n",
    "    bin_min: int = min(sc_counts) - 1\n",
    "    bin_max: int = max(sc_counts) + 1\n",
    "    bin_edges = np.linspace(bin_min, bin_max, num_bins + 1)\n",
    "\n",
    "    # Get the bin each family falls into\n",
    "    family_bin_assignments: np.ndarray = np.digitize(sc_counts, bin_edges) - 1\n",
    "    \n",
    "    # Return families in each bucket\n",
    "    for bin_index in range(num_bins):\n",
    "        family_names_in_bin = np.array(list(family_sc_counts.keys()))\\\n",
    "            [family_bin_assignments == bin_index]\n",
    "        \n",
    "        if len(family_names_in_bin) > 0:\n",
    "            family_counts_in_bin = np.array(list(family_sc_counts.values()))\\\n",
    "                [family_bin_assignments == bin_index]\n",
    "        \n",
    "            yield dict(zip(\n",
    "                map(str, family_names_in_bin),\n",
    "                map(int, family_counts_in_bin)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_families_for_phylum(sc_counts_by_family, target_family_count):\n",
    "    num_bins = target_family_count\n",
    "    num_families_remaining_for_phylum = target_family_count\n",
    "\n",
    "    for j, family_bin_sc_counts in enumerate(gen_family_bins_with_ascending_size(sc_counts_by_family, num_bins)):\n",
    "        num_bins_remaining = num_bins - j\n",
    "        max_num_families_per_bucket = math.floor(num_families_remaining_for_phylum / num_bins_remaining)\n",
    "\n",
    "        # Sort families descending by [(species, county)] count\n",
    "        family_bin_sc_counts = list(sorted(family_bin_sc_counts.items(), key=lambda kv: (kv[1], kv[0]), reverse=True))\\\n",
    "            [:max_num_families_per_bucket]\n",
    "        \n",
    "        bin_families, _ = zip(*family_bin_sc_counts)\n",
    "        yield from bin_families\n",
    "        \n",
    "        num_families_remaining_for_phylum -= len(bin_families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phylum 1 : anthocerotophyta (max 24 familiies)\n",
      "- dendrocerotaceae\n",
      "- anthocerotaceae\n",
      "- notothyladaceae\n",
      "  3 families sampled\n",
      "Phylum 2 : charophyta (max 27 familiies)\n",
      "- mesotaeniaceae\n",
      "- zygnemataceae\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfamily\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m phylum_family_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_species_county_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkingdom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspecies_counties_by_family\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_records_per_family\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mget_species_county_records\u001b[0;34m(kingdom, sc_pairs, count)\u001b[0m\n\u001b[1;32m     13\u001b[0m shuffle_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(sc_pairs))[:count]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sc \u001b[38;5;129;01min\u001b[39;00m (sc_pairs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m shuffle_index):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mget_record_for_species_county\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkingdom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mget_record_for_species_county\u001b[0;34m(kingdom, species_county)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_record_for_species_county\u001b[39m(kingdom: \u001b[38;5;28mstr\u001b[39m, species_county: SpeciesCounty) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_idigbio_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkingdom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkingdom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscientificname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_county\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcounty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_county\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcounty\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mget_idigbio_records\u001b[0;34m(rq, limit, gt_uuid, api)\u001b[0m\n\u001b[1;32m     31\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m\"\u001b[39m: gt_uuid}}\n\u001b[1;32m     32\u001b[0m     data \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msort\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masc\u001b[39m\u001b[38;5;124m\"\u001b[39m }]\n\u001b[1;32m     34\u001b[0m     }\n\u001b[0;32m---> 36\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mapi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/search/records\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/mambaforge/envs/dataset/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_families_remaining = families_per_kingdom\n",
    "\n",
    "with open(records_path, \"w\") as f:\n",
    "    for i, (phylum, phylum_family_count) in enumerate(phylum_family_counts.items()):\n",
    "        num_phyla_remaining = len(phyla) - i\n",
    "        target_family_count = math.floor(num_families_remaining / num_phyla_remaining)\n",
    "\n",
    "        print(f\"Phylum {i+1:<2}: {phylum} (max {target_family_count} familiies)\")\n",
    "\n",
    "        species_counties_by_family = {\n",
    "            family: get_family_species_county_pairs(kingdom, family)\n",
    "            for family in phylum_family_candidates[phylum]\n",
    "        }\n",
    "\n",
    "        # Filter out families with too few records\n",
    "        sc_counts_by_family = {\n",
    "            family: len(scs)\n",
    "            for family, scs in species_counties_by_family.items()\n",
    "            if len(scs) >= min_records_per_family\n",
    "        }\n",
    "\n",
    "        phylum_family_count = 0\n",
    "        for family in iter_families_for_phylum(sc_counts_by_family, target_family_count):\n",
    "            print(f\"- {family}\")\n",
    "            phylum_family_count += 1\n",
    "\n",
    "            for record in get_species_county_records(\n",
    "                    kingdom, \n",
    "                    species_counties_by_family[family],\n",
    "                    max_records_per_family\n",
    "                ):\n",
    "                json.dump(record, f)\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        num_families_remaining -= phylum_family_count\n",
    "        print(f\"  {phylum_family_count} families sampled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
